{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecular Dynamics Steps\n",
    "##### Step 1: Prepare \n",
    "##### Step 2: Relax/minimize\n",
    "##### Step 3: Heat/Equilibrate \n",
    "##### <span style=\"color:blue\">Step 4: Production </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production runs\n",
    "###### This will be the data collected for analysis! The essential difference between production and equilibration is simply that we plan to analyze the production data. You never want to perform production runs immediately after altering something about your system (temperature, number of molecules, box size, etc). If any of that is done you must give your system time to equilibrate. Otherwise, your data will contain artifacts, and thermodynamic property calculations will not hold true because your system was not at equilibrium. It is common practive to discard some initial chunk of production run trajectory to further ensure the data you analyze is of the equilibrated system. \n",
    "\n",
    "##### Possibly one of the most difficult decisions now is to decide what data to store, and how often to store it. One thing to keep in mind is the time correlation of variables form your simulation. MD observations are time-correlated, therefore it is unneccesary and problematic (in a redundant manner) to store data at each point in time. You must store data in time steps less than the autocorrelation for that specific observable. Alas, we would have no way of knowing the autocorrelation time of a variable until we determine it from simulation, so it is essentially unavoidable to store some redundant data. \n",
    "\n",
    "\n",
    "##### I generated 2.5 T of data :') in my 2nd year. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRO TIP: You should visualize your system during the heating and equilibration steps to ensure nothing wonky happens (like the system blowing up!) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the 'Trajectory Analysis' Jupyter Notebook for a tutorial on how to visualize trajectory, but keep in mind you probably DON'T want to strip your water molecules at this point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### production.in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPT; no constraints; 10 ns chunks <br />\n",
    "&cntrl <br />\n",
    " imin=0, #no minimization <br />\n",
    " irest=1, #flag to restart simulation, reading positions and velocities from a previous restart file <br />\n",
    " ntx=5, #read coordinates and velocities from a previous restart file <br />\n",
    " ntpr=2500, #print MD progress every 2500 steps <br />\n",
    " ntwr=5000, #restart file written every 50000 steps <br />\n",
    " ntwx=2500, #write out coordinates every 2500 steps <br />\n",
    " nstlim=5000000, #number of MD steps <br />\n",
    " dt=0.002, #timestep in picoseconds <br />\n",
    " ntt=3, #Langevin dynamics <br />\n",
    " temp0=303.0, <br />\n",
    " ig=-1, <br />\n",
    " gamma_ln=2, <br />\n",
    " ntp=1, #pressure regulation. 1=md with isotropic position scaling <br />\n",
    " barostat=2, #Monte Carlo barostat <br />\n",
    " pres0=1.0,#bars <br />\n",
    " ntc=2, #bonds involving H are constrained according to SHAKE  <br />\n",
    " ntf=2, #bond interactions with H omitted <br />\n",
    " ntb=2, #periodic boundary conditions are imposed for constant pressure <br />\n",
    " cut=12.0, #nonbonded cutoff in A <br />\n",
    " ioutfm=1,#binary NetCDF trajectory. Binaries are smaller, higher precision, and faster to read and write.\n",
    " iwrap=1, #the coordinates written to the rst and trajectory files will be 'wrapped' into a primary box. Has no effect on energy or forces, it's more of a visual thing. This CAN alter diffusion types of acalculations, so in such cases you want = 0. If you are running long trajectories this might be necessary to keep the coordinate output from overflowing the file formats, resulting in huge files. <br />\n",
    "/ <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run:\n",
    "    \n",
    "AMBERHOME/bin/pmemd.cuda -O -i ../Production.in -o 1gpw_holo_wt.prod.prod.out -r 1gpw_holo_wt.prod.prod.rst -x 1gpw_holo_wt.prod.prod.cd -c ../Production_correct_ntwx.prev_prod/1gpw_holo_wt.prod.prev_prod.rst -p ../1gpw_holo_wt.prmtop -inf 1gpw_holo_wt.prod.prod.mdinfo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
